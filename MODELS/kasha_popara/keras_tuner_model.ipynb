{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "import keras\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = 'D:\\FINKI\\8_dps\\Project\\DATA\\MODELS_DATA\\\\base_models_all_dft_coefficients'\n",
    "train = pd.read_csv(f'{data_dir}\\\\segments_10s_train.csv')\n",
    "test = pd.read_csv(f'{data_dir}\\\\segments_10s_test.csv')\n",
    "\n",
    "y_train = train.pop['episode']\n",
    "y_test = test.pop['episode']\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "  model = keras.models.Sequential()\n",
    "\n",
    "  num_layers = hp.Int('num_layers', 1, 4, step = 1)\n",
    "  num_nodes_first_layer = hp.Int('num_nodes_first_layer', 20, 200)\n",
    "  shrinkage_factor = hp.float('shrinkage_factor', 0.7, 0.3)\n",
    "  learning_rate = hp.Float('learning_rate', 0.001, 0.5)\n",
    "  decay = hp.Float('decay', 0.001, 0.1)\n",
    "  optimizer = hp.Choice('optimizer', ['Adam', 'Nadam', 'RMSProp', 'Adagrad'])\n",
    "\n",
    "  model.add(keras.layers.Dense(units = layer_dict['units'],\n",
    "                      input_shape = (self.split_sets['X_train'].shape[1],),\n",
    "                      activation = layer_dict['activation'],\n",
    "                      kernel_initializer = self.hypermethods['initializer'],\n",
    "                      kernel_regularizer = self.hypermethods['regularizer']))\n",
    "\n",
    "  for layer_iter in range(num_layers):\n",
    "      model.add(keras.layers.Dense(units = layer_dict['units'],\n",
    "                      input_shape = (self.split_sets['X_train'].shape[1],),\n",
    "                      activation = layer_dict['activation'],\n",
    "                      kernel_initializer = self.hypermethods['initializer'],\n",
    "                      kernel_regularizer = self.hypermethods['regularizer']))\n",
    "\n",
    "\n",
    "  model_type = hp.Choice('model_type', ['random_forest', 'ridge'])\n",
    "  if model_type == 'random_forest':\n",
    "    model = ensemble.RandomForestClassifier(\n",
    "        n_estimators=hp.Int('n_estimators', 10, 50, step=10),\n",
    "        max_depth=hp.Int('max_depth', 3, 10))\n",
    "  else:\n",
    "    model = linear_model.RidgeClassifier(\n",
    "        alpha=hp.Float('alpha', 1e-3, 1, sampling='log'))\n",
    "  return model\n",
    "\n",
    "tuner = kt.tuners.Sklearn(\n",
    "    oracle=kt.oracles.BayesianOptimization(\n",
    "        objective=kt.Objective('score', 'max'),\n",
    "        max_trials=10),\n",
    "    hypermodel=build_model,\n",
    "    scoring=metrics.make_scorer(metrics.accuracy_score),\n",
    "    cv=model_selection.StratifiedKFold(5),\n",
    "    directory='.',\n",
    "    project_name='my_project')\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "\n",
    "tuner.search(X_train, y_train)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
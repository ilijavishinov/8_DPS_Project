{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from comet_ml import Experiment, OfflineExperiment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import testing_utils\n",
    "import random\n",
    "\n",
    "search_space_dir = 'search_spaces'\n",
    "\n",
    "ALGORITHM = 'ANN'\n",
    "DS = 'DS2'\n",
    "SEGMENTS_LENGTH = 10\n",
    "NUM_ITER = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = F'RandomSearch_{ALGORITHM}_{DS}_{SEGMENTS_LENGTH}s'\n",
    "\n",
    "data_dir = f'D:\\FINKI\\8_dps\\Project\\DATA\\MODELS_DATA\\\\afdb\\DS1'\n",
    "X_train = pd.read_csv(f'{data_dir}\\\\segments_{SEGMENTS_LENGTH}s_train.csv')\n",
    "X_test = pd.read_csv(f'{data_dir}\\\\segments_{SEGMENTS_LENGTH}s_test.csv')\n",
    "\n",
    "y_train = X_train.pop('episode')\n",
    "y_test = X_test.pop('episode')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "search_space = dict(\n",
    "    model_architecture = [1,2,3,4,5],\n",
    "    batch_size = [10000, 5000, 1000],\n",
    "    optimizer = ['adam', 'ftrl', 'rmsprop'],\n",
    "    loss = ['categorical_hinge', 'binary_crossentropy', 'poisson', 'kl_divergence'],\n",
    "    initializer = ['variance_scaling', 'glorot_normal'],\n",
    "    activation = ['relu', 'sigmoid']\n",
    ")\n",
    "\n",
    "# combinations\n",
    "keys, values = zip(*search_space.items())\n",
    "combinations_dicts = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "model_names = [f'{EXPERIMENT_ID}_{i + 1}' for i in range(len(combinations_dicts))]\n",
    "combinations_df = pd.DataFrame(combinations_dicts)\n",
    "combinations_df.insert(0, 'Model', model_names)\n",
    "combinations_df['Trained'] = 'No'\n",
    "\n",
    "search_space_path = f'{search_space_dir}\\\\search_space_{EXPERIMENT_ID}.xlsx'\n",
    "combinations_df.to_excel(search_space_path, index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/8-dps/ann-afib/d4de32984c9e4448a7826bfbde653aba\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Name : RandomSearch_ANN_DS2_10s_5\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (16 MB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Native output logging mode is not available, fallbacking on basic output logging\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/8-dps/ann-afib/526e861f95624fad8288fbf418e2e032\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-ab5bffab3f0f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msearch_space_model\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'model_architecture'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m         model.add(Dense(units = int(2 * X_train.shape[1]/3), input_shape = X_train.shape[1],\n\u001B[0m\u001B[0;32m     31\u001B[0m                         \u001B[0mactivation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msearch_space_model\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'activation'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m                         kernel_initializer = search_space_model['activation']))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "more_models_left_to_train = True\n",
    "results_list = list()\n",
    "\n",
    "while NUM_ITER > 0:\n",
    "    NUM_ITER -= 1\n",
    "\n",
    "    search_space_state = pd.read_excel(search_space_path)\n",
    "\n",
    "    random_index = random.choice(list(search_space_state.loc[search_space_state['Trained'] == 'No'].index))\n",
    "    search_space_model = search_space_state.loc[search_space_state['Trained'] == 'No'].loc[random_index]\n",
    "\n",
    "    comet_experiment = Experiment(\n",
    "        api_key = 'A8Lg71j9LtIrsv0deBA0DVGcR',\n",
    "        project_name = f'{ALGORITHM}-afib',\n",
    "        workspace = \"8_dps\",\n",
    "        auto_output_logging = 'native',\n",
    "    )\n",
    "    comet_experiment.set_name(search_space_model['Model'])\n",
    "    comet_experiment.add_tags([DS, SEGMENTS_LENGTH, ALGORITHM])\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "\n",
    "    if search_space_model['model_architecture'] == 1:\n",
    "        model.add(Dense(units = int(X_train.shape[1]/2), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    if search_space_model['model_architecture'] == 2:\n",
    "        model.add(Dense(units = int(2 * X_train.shape[1]/3), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = int(X_train.shape[1]/3), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    if search_space_model['model_architecture'] == 3:\n",
    "        model.add(Dense(units = int(3 * X_train.shape[1]/4), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = int(X_train.shape[1]/2), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = int(3 * X_train.shape[1]/2), input_shape = X_train.shape[1],\n",
    "                        activation = search_space_model['activation'],\n",
    "                        kernel_initializer = search_space_model['activation']))\n",
    "        model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(loss = search_space_model['loss'],\n",
    "                  optimizer = search_space_model['optimizer'],\n",
    "                  metrics= [\"accuracy\"])\n",
    "\n",
    "    with comet_experiment.train():\n",
    "\n",
    "        model.fit(\n",
    "            x = X_train,\n",
    "            y = y_train,\n",
    "            epochs = 1500,\n",
    "            batch_size = 1000,\n",
    "            validation_split = 0.1,\n",
    "            callbacks = [keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 10, patience = 100)],\n",
    "            verbose = 10,\n",
    "            workers = 2\n",
    "        )\n",
    "\n",
    "    with comet_experiment.test():\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose = 10, batch_size = 1000000, workers = 2)\n",
    "\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    comet_experiment.log_metrics(testing_utils.testing_metrics(y_test = y_test, y_pred = y_pred))\n",
    "\n",
    "    model.save(f'saved_models/{search_space_model[\"Model\"]}.h5')\n",
    "\n",
    "    comet_experiment.end()\n",
    "\n",
    "    search_space_state = pd.read_excel(search_space_path)\n",
    "    search_space_state.loc[search_space_state['Model'] == search_space_model['Model'], 'Trained'] = 'Yes'\n",
    "    search_space_state.to_excel(search_space_path, index = False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
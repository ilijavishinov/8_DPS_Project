{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ann_data_dir = 'D:\\FINKI\\8_dps\\Project\\DATA\\physionet_dbs\\cudb\\\\annotations_systemized'\n",
    "samp_data_dir = 'D:\\FINKI\\8_dps\\Project\\DATA\\physionet_dbs\\cudb\\samples'\n",
    "write_data_dir = 'D:\\FINKI\\8_dps\\Project\\DATA\\physionet_dbs\\cudb\\\\uniclass_episode_signals_250hz'\n",
    "\n",
    "if not os.path.exists(write_data_dir):\n",
    "    os.makedirs(write_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cu01.csv\n",
      "cu02.csv\n",
      "cu03.csv\n",
      "cu04.csv\n",
      "cu05.csv\n",
      "cu06.csv\n",
      "cu07.csv\n",
      "cu08.csv\n",
      "cu09.csv\n",
      "cu10.csv\n",
      "cu11.csv\n",
      "cu12.csv\n",
      "cu13.csv\n",
      "cu14.csv\n",
      "cu15.csv\n",
      "cu16.csv\n",
      "cu17.csv\n",
      "cu18.csv\n",
      "cu19.csv\n",
      "cu20.csv\n",
      "cu21.csv\n",
      "cu22.csv\n",
      "cu23.csv\n",
      "cu24.csv\n",
      "cu25.csv\n",
      "cu26.csv\n",
      "cu27.csv\n",
      "cu28.csv\n",
      "cu29.csv\n",
      "cu30.csv\n",
      "cu31.csv\n",
      "cu32.csv\n",
      "cu33.csv\n",
      "cu34.csv\n",
      "cu35.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(ann_data_dir):\n",
    "    file = str(file)\n",
    "    print(file)\n",
    "\n",
    "    ann_file = pd.read_csv(f'{ann_data_dir}\\\\{file}')\n",
    "    samp_file = pd.read_csv(f'{samp_data_dir}\\\\{file}')\n",
    "    samp_file.columns = ['sample_idx', 'ecg']\n",
    "\n",
    "    # beat annotations are irrelevant, so they are dismissed\n",
    "    ann_file = ann_file[~ann_file['episode'].isna()].reset_index(drop = True)\n",
    "\n",
    "\n",
    "    # the current episode that the segments belong to, and is kept if noise comes as an episode annotation\n",
    "    ongoing_episode = None\n",
    "\n",
    "    # iterating episodes\n",
    "    for ann_idx, ann_row in ann_file.iterrows():\n",
    "\n",
    "        # if last noise annotation, assume the rest of the signal is fine and noiseless\n",
    "        if ann_row['episode'] == 'NOISE' and ann_idx == ann_file.shape[0] - 1:\n",
    "            episode = ongoing_episode\n",
    "            episode_start_sample = ann_row['sample_idx'] + 1\n",
    "        # if there are noise anns following the current noise ann, because of ambiguity, dismiss the signal\n",
    "        elif ann_row['episode'] == 'NOISE' and ann_file.iloc[ann_idx + 1]['episode'] == 'NOISE':\n",
    "            episode = ongoing_episode\n",
    "            episode_start_sample = ann_row['sample_idx'] + 1\n",
    "        elif ann_row['episode'] == 'NOISE' and ann_file.iloc[ann_idx + 1]['episode'] != 'NOISE':\n",
    "            continue\n",
    "        # in the normal case when a rhythm episode begins\n",
    "        else:\n",
    "            episode = ann_row['episode']\n",
    "            ongoing_episode = ann_row['episode']\n",
    "            episode_start_sample = ann_row['sample_idx']\n",
    "\n",
    "        # if last episode, go to end of file, otherwise end is the start of next episode\n",
    "        if ann_idx == ann_file.shape[0] - 1:\n",
    "            episode_end_sample = samp_file.iloc[-1]['sample_idx']\n",
    "        else:\n",
    "            episode_end_sample = ann_file.iloc[ann_idx + 1]['sample_idx'] - 1\n",
    "\n",
    "        clean_episode_signal = samp_file[\n",
    "            (samp_file['sample_idx'] >= episode_start_sample) &\n",
    "            (samp_file['sample_idx'] <= episode_end_sample)\n",
    "        ]\n",
    "\n",
    "        clean_episode_signal.to_csv(\n",
    "                f'{write_data_dir}\\\\'\n",
    "                f'{file.replace(\".csv\",\"\")}_'\n",
    "                f'{episode.replace(\"(\",\"\")}_'\n",
    "                f'{ann_idx}'\n",
    "        )\n",
    "\n",
    "        # break\n",
    "    #\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "|"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}